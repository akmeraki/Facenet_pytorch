{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "import torch\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms\n",
    "from src.utility import show_img "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Download VGGface2 and LFW datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download and unzip Vggface2 dataset \n",
    "# Try to download from academic torrents \n",
    "root = os.getcwd()\n",
    "extract_lfw_dir = 'data/VGG-Face2 '\n",
    "filename = 'vggface2_train.zip'\n",
    "\n",
    "# shutil.unpack_archive(filename, extract_lfw_dir)\n",
    "# os.remove(os.path.join(root,'data',filename))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloading & Exploring the Labelled faces in the wild (LFW) dataset from Kaggle \n",
    "# Kaggle datasets download -d atulanandjha/lfwpeople -p path \n",
    "# Kaggle datasets download -d jessicali9530/lfw-dataset -p path \n",
    "\n",
    "root = os.getcwd()\n",
    "extract_lfw_dir = 'data/lfwpeople'\n",
    "filename = 'lfwpeople.zip'\n",
    "\n",
    "# unzip and remove zip file \n",
    "# shutil.unpack_archive(filename, extract_lfw_dir)\n",
    "# os.remove(os.path.join(root,'data',filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the VGG Face2 dataset\n",
    "\n",
    "transforms = transforms.Compose([transforms.ToTensor(),transforms.Resize((204,204))])\n",
    "\n",
    "VGG_folder = os.path.join(root,'data','VGG-Face2','data')\n",
    "vggface2 = ImageFolder(VGG_folder, transform=transforms)\n",
    "\n",
    "print(vggface2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = torch.utils.data.DataLoader(vggface2, batch_size=64, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_img(dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Extract the faces from the images using MTCNN face detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/VGG-Face2/data\\test_list.txt is not valid image. Expected extension: .jpg, .jpeg, .png\n",
      "data/VGG-Face2/data\\train_list.txt is not valid image. Expected extension: .jpg, .jpeg, .png\n",
      "Multiple faces detected on image data/VGG-Face2/data\\test\\n000001\\0027_03.jpg\n",
      "Multiple faces detected on image data/VGG-Face2/data\\test\\n000001\\0029_01.jpg\n",
      "Multiple faces detected on image data/VGG-Face2/data\\test\\n000001\\0034_02.jpg\n",
      "Multiple faces detected on image data/VGG-Face2/data\\test\\n000001\\0075_01.jpg\n",
      "No face detected on image data/VGG-Face2/data\\test\\n000001\\0097_09.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"src/mtcnn.py\", line 78, in <module>\n",
      "    detect_and_store(path, final_path, args.resize)\n",
      "  File \"src/mtcnn.py\", line 31, in detect_and_store\n",
      "    if boxes.shape[0] == 1:\n",
      "AttributeError: 'NoneType' object has no attribute 'shape'\n"
     ]
    }
   ],
   "source": [
    "# We have to extract the face from the image and save it in a new folder. This removes the background and other irrelevant information.\n",
    "\n",
    "!python src/mtcnn.py --root-dir data/VGG-Face2/data --final-dir data/VGGface2_train/ --resize 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new csv file  \n",
    "!python src/csv_file_creation.py --root-dir data/VGG-Face2/data --final-file VGG-Face2.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8a9c223cf103f8e4bd3016efd356f952fbd4651dca158957834db2968df2eff7"
  },
  "kernelspec": {
   "display_name": "Python 3.6.13 ('env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
